---
---

@INPROCEEDINGS{kaichen,
abbr = {ICRA},
author={Christopher Ford and Kaichen Shi and Nathan Lepora and Efi Psomopoulou},
booktitle={IEEE International Conference on Robotics and Automation}, 
title={How to Train your Tactile Model: Tactile Perception with Multi-fingered Robot Hands}, 
year={2026},
volume={},
number={},
altmetric = {true},
dimensions={true},
pages={},
archivePrefix={arXiv},
primaryClass={cs.RO},
selected = {true},
note={accepted}
}

@INPROCEEDINGS{dhillon,
abbr = {ICRA},
author={Dhillon Merritt and Christopher Ford and Haoran Li and Malia Smith and Zhixing Chen and Efi Psomopoulou and Nathan Lepora},
booktitle={IEEE International Conference on Robotics and Automation}, 
title={SoftHand Model-W: A 3D-Printed, Anthropomorphic, Underactuated Robot Hand with Integrated Wrist and Carpal Tunnel}, 
year={2026},
volume={},
number={},
altmetric = {true},
dimensions={true},
pages={},
archivePrefix={arXiv},
primaryClass={cs.RO},
note={accepted}
}

@misc{lu2025neuromorphicincipientslipdetection,
  abbr = {RAL},
  title={A Neuromorphic Incipient Slip Detection System using Papillae Morphology}, 
  author={Yanhui Lu and Zeyu Deng and Stephen J. Redmond and Efi Psomopoulou and Benjamin Ward-Cherrier},
  journal={IEEE Robotics and Automation Letters}, 
  year={2026},
  volume={11},
  number={3},
  pages={2802-2809},
  doi={10.1109/LRA.2026.3655298},
  arxiv={2509.09546},
  archivePrefix={arXiv},
  primaryClass={cs.RO},
  altmetric = {true},
  dimensions={true}
}

@ARTICLE{11297907,
  abbr = {RAM},
  author={Psomopoulou, Efi and Figueroa, Nadia and Chalvatzaki, Georgia},
  journal={IEEE Robotics & Automation Magazine}, 
  title={WiRA: Reshaping Recognition in Robotics and Automation for Gender Equity [Women in Engineering]}, 
  year={2025},
  volume={32},
  number={4},
  pages={118-120},
  doi={10.1109/MRA.2025.3617625}}


@inproceedings{field2025texttouch,
abbr = {CoRL},
title={Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions},
author={Harrison Field and Max Yang and Yijiong Lin and Efi Psomopoulou and David A.W. Barton and Nathan F. Lepora},
booktitle={9th Annual Conference on Robot Learning, Proceedings of Machine Learning Research},
year={2025},
altmetric = {true},
dimensions={true},
html={https://openreview.net/forum?id=U9zcbQVDGa},
abstract = {Large language models (LLMs) are beginning to automate reward design for dexterous manipulation. However, no prior work has considered tactile sensing, which is known to be critical for human-like dexterity. We present Text2Touch, bringing LLM-crafted rewards to the challenging task of multi-axis in-hand object rotation with real-world vision based tactile sensing in palm-up and palm-down configurations. Our prompt engineering strategy scales to over 70 environment variables, and sim-to-real distillation enables successful policy transfer to a tactile-enabled fully actuated four-fingered dexterous robot hand. Text2Touch significantly outperforms a carefully tuned human-engineered baseline, demonstrating superior rotation speed and stability while relying on reward functions that are an order of magnitude shorter and simpler. These results illustrate how LLM-designed rewards can significantly reduce the time from concept to deployable dexterous tactile skills, supporting more rapid and scalable multimodal robot learning.},
website = {https://text2touch.github.io/project-website/}
}

@ARTICLE{11134134,
  abbr = {SENSORS},
  author={Li, Haoran and Lin, Yijiong and Lu, Chenghua and Yang, Max and Psomopoulou, Efi and Lepora, Nathan F.},
  journal={IEEE Sensors Journal}, 
  title={Classification of Vision-Based Tactile Sensors: A Review}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Vision-based tactile sensors (VBTS) have gained widespread application in robotic hands, grippers and prosthetics due to their high spatial resolution, low manufacturing costs, and ease of customization. While VBTSs have common design features, such as a camera module, they can differ in a rich diversity of sensing principles, material compositions, multimodal approaches, and data interpretation methods. Here, we propose a novel classification of VBTS that categorizes the technology into two primary sensing principles based on the underlying transduction of contact into a tactile image: the Marker-Based Transduction Principle and the Intensity-Based Transduction Principle. Marker-Based Transduction interprets tactile information by detecting marker displacement and changes in marker density. In contrast, Intensity-Based Transduction maps external disturbances with variations in pixel values. Depending on the design of the contact module, Marker-Based Transduction can be further divided into two subtypes: Simple Marker-Based (SMB) and Morphological Marker-Based (MMB) mechanisms. Similarly, the Intensity-Based Transduction Principle encompasses the Reflective Layer-based (RLB) and Transparent Layer-Based (TLB) mechanisms. This paper provides a comparative study of the hardware characteristics of these four types of sensors including various combination types, and discusses the commonly used methods for interpreting tactile information. This comparison reveals some current challenges faced by VBTS technology and directions for future research.},
  keywords={Sensors;Robot sensing systems;Robots;Tactile sensors;Lighting;Intelligent sensors;Reviews;Cameras;Skin;Image sensors;Vision-based tactile sensors (VBTS);Optical tactile sensors},
  doi={10.1109/JSEN.2025.3599236},
  ISSN={1558-1748},
  month={},
  arxiv={2509.02478},
  archivePrefix={arXiv},
  primaryClass={cs.RO},
  html={https://arxiv.org/abs/2509.02478}, 
  altmetric = {true},
  dimensions={true},
  selected = {true},}


@INPROCEEDINGS{LEGO,
  abbr = {IROS},
  author={Lepora, Jared and Li, Haoran and Psomopoulou, Efi and Lepora, Nathan},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO® MINDSTORMS®}, 
  year={2025},
  volume={},
  number={},
  pages={21481-21486},
  doi={10.1109/IROS60139.2025.11246837},
  altmetric = {true},
  dimensions={true}
  }


@ARTICLE{RanPreprint,
abbr = {IJRR},
  author={Li, Haoran and Ford, Christopher J and Lu, Chenghua and Lin, Yijiong and Bianchi, Matteo and Catalano, Manuel G and Psomopoulou, Efi and Lepora, Nathan F},
  journal={The International Journal of Robotics Research}, 
  title={Tactile SoftHand-A: 3D-Printed, Tactile, Highly-underactuated, Anthropomorphic Robot Hand with an Antagonistic Tendon Mechanism}, 
  year={2025},
  altmetric = {true},
  dimensions={true},
  eprint={2406.12731},
  arxiv = {2406.12731},
  website={https://github.com/HaoranLi-Data/Tactile_SoftHand_A},
  pdf={https://arxiv.org/pdf/2406.12731},
  archivePrefix={arXiv},
  primaryClass={cs.RO},
  video={https://www.youtube.com/embed/VV3hCQBoDRs?si=0hrpPtNo26ZlM7WF},
  url={https://arxiv.org/abs/2406.12731},
  html={https://arxiv.org/abs/2406.12731},
  note={accepted},
  abstract={For tendon-driven multi-fingered robotic hands, ensuring grasp adaptability while minimizing the number of actuators needed to provide human-like functionality is a challenging problem. Inspired by the Pisa/IIT SoftHand, this paper introduces a 3D-printed, highly-underactuated, five-finger robotic hand named the Tactile SoftHand-A, which features only two actuators. The dual-tendon design allows for the active control of specific (distal or proximal interphalangeal) joints to adjust the hand's grasp gesture. We have also developed a new design of fully 3D-printed tactile sensor that requires no hand assembly and is printed directly as part of the robotic finger. This sensor is integrated into the fingertips and combined with the antagonistic tendon mechanism to develop a human-hand-guided tactile feedback grasping system. The system can actively mirror human hand gestures, adaptively stabilize grasp gestures upon contact, and adjust grasp gestures to prevent object movement after detecting slippage. Finally, we designed four different experiments to evaluate the novel fingers coupled with the antagonistic mechanism for controlling the robotic hand's gestures, adaptive grasping ability, and human-hand-guided tactile feedback grasping capability. The experimental results demonstrate that the Tactile SoftHand-A can adaptively grasp objects of a wide range of shapes and automatically adjust its gripping gestures upon detecting contact and slippage. Overall, this study points the way towards a class of low-cost, accessible, 3D-printable, underactuated human-like robotic hands, and we openly release the designs to facilitate others to build upon this work. This work is Open-sourced.},
}

@ARTICLE{10972061,
  abbr = {T-RO},
  author={Ford, Christopher J. and Li, Haoran and Catalano, Manuel G. and Bianchi, Matteo and Psomopoulou, Efi and Lepora, Nathan F.},
  journal={IEEE Transactions on Robotics}, 
  title={Shear-Based Grasp Control for Multifingered Underactuated Tactile Robotic Hands}, 
  year={2025},
  volume={41},
  number={},
  pages={3113-3128},
  keywords={Robots;Hands;Sensors;Force;Tactile sensors;Grasping;Optical sensors;Optical imaging;Optical feedback;Accuracy;Manipulators;robot control;tactile sensors},
  doi={10.1109/TRO.2025.3563046},
  arxiv={2503.17501},
  pdf={https://arxiv.org/pdf/2503.17501},
  url={https://ieeexplore.ieee.org/document/10972061},
  abstract={This article presents a shear-based control scheme for grasping and manipulating delicate objects with a Pisa/IIT anthropomorphic SoftHand equipped with soft biomimetic tactile sensors on all five fingertips. These “microTac” tactile sensors are miniature versions of the TacTip vision-based tactile sensor, and can extract precise contact geometry and force information at each fingertip for use as feedback into a controller to modulate the grasp while a held object is manipulated. Using a parallel processing pipeline, we asynchronously capture tactile images and predict contact pose and force from multiple tactile sensors. Consistent pose and force models across all sensors are developed using supervised deep learning with transfer learning techniques. We then develop a grasp control framework that uses contact force feedback from all fingertip sensors simultaneously, allowing the hand to safely handle delicate objects even under external disturbances. This control framework is applied to several grasp-manipulation experiments: First, retaining a flexible cup in a grasp without crushing it under changes in object weight; Second, a pouring task where the center of mass of the cup changes dynamically; and third, a tactile-driven leader-follower task where a human guides a held object. These manipulation tasks demonstrate more human-like dexterity with underactuated robotic hands by using fast reflexive control from tactile sensing.},
  altmetric = {true},
  dimensions={true},
  selected = {true}}

@ARTICLE{10794534,
  abbr = {RAM},
  author={Billard, Aude and Psomopoulou, Efi and Chalvatzaki, Georgia},
  journal={IEEE Robotics & Automation Magazine}, 
  title={The RAS Women in Engineering Committee in Conversation With RAS President Aude Billard [President’s Message]}, 
  year={2024},
  volume={31},
  altmetric = {true},
  dimensions={true},
  number={4},
  pages={6-8},
  keywords={},
  url={https://ieeexplore.ieee.org/abstract/document/10794534},
  doi={10.1109/MRA.2024.3481768}}


@INPROCEEDINGS{10802651,
  abbr = {IROS},
  author={Mao, Xiaofeng and Xu, Yucheng and Wen, Ruoshi and Kasaei, Mohammadreza and Yu, Wanming and Psomopoulou, Efi and Lepora, Nathan F. and Li, Zhibin},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Efficient Tactile Sensing-based Learning from Limited Real-world Demonstrations for Dual-arm Fine Pinch-Grasp Skills}, 
  year={2024},
  volume={},
  number={},
  eprint={2307.04619},
  altmetric = {true},
  dimensions={true},
  arxiv={2307.04619},
  url={https://ieeexplore.ieee.org/abstract/document/10802651},
  pages={5112-5119},
  keywords={Imitation learning;Perturbation methods;Autoencoders;Grasping;Robot sensing systems;Feature extraction;Robustness;Sensors;Data mining;Intelligent robots},
  doi={10.1109/IROS58592.2024.10802651},
  }


@inproceedings{yang2024anyrotate,
abbr = {CoRL},
title={AnyRotate: Gravity-Invariant In-Hand Object Rotation with Sim-to-Real Touch},
author={Max Yang and Chenghua Lu and Alex Church and Yijiong Lin and Christopher J. Ford and Haoran Li and Efi Psomopoulou and David A.W. Barton and Nathan F. Lepora},
booktitle={8th Annual Conference on Robot Learning, Proceedings of Machine Learning Research},
year={2024},
altmetric = {true},
dimensions={true},
url={https://openreview.net/forum?id=8Yu0TNJNGK},
html = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000729827&partnerID=40&md5=84efdbf87b0a5266294d200cdc276912},
abstract = {Human hands are capable of in-hand manipulation in the presence of different hand motions. For a robot hand, harnessing rich tactile information to achieve this level of dexterity still remains a significant challenge. In this paper, we present AnyRotate, a system for gravity-invariant multi-axis in-hand object rotation using dense featured sim-to-real touch. We tackle this problem by training a dense tactile policy in simulation and present a sim-to-real method for rich tactile sensing to achieve zero-shot policy transfer. Our formulation allows the training of a unified policy to rotate unseen objects about arbitrary rotation axes in any hand direction. In our experiments, we highlight the benefit of capturing detailed contact information when handling objects with varying properties. Interestingly, despite not having explicit slip detection, we found rich multi-fingered tactile sensing can implicitly detect object movement within grasp and provide a reactive behavior that improves the robustness of the policy. The project website can be found at this https URL.},
selected = {true},
website = {https://maxyang27896.github.io/anyrotate/},
video = {https://www.youtube.com/embed/0pli0-QvTgc?si=It2WrWhHdWjJwblU},
pdf = {https://arxiv.org/pdf/2405.07391}
}


@ARTICLE{10496158RAN,
abbr = {RA-L},
  author={Li, Haoran and Nam, Saekwang and Lu, Zhenyu and Yang, Chenguang and Psomopoulou, Efi and Lepora, Nathan F.},
  journal={IEEE Robotics and Automation Letters}, 
  title={BioTacTip: A Soft Biomimetic Optical Tactile Sensor for Efficient 3D Contact Localization and 3D Force Estimation}, 
  year={2024},
  volume={9},
  number={6},
  pages={5314-5321},
  altmetric = {true},
  dimensions={true},
  video={https://www.youtube.com/embed/zkgVg-ZGmQg?si=Z_ySDqiAI42Ex76q},
  award = {Best Poster Award at ViTac ICRA 2024},
  award_name = {Best Poster},
  keywords={Robot sensing systems;Skin;Tactile sensors;Force;Cameras;Biomimetics;Computational modeling;Biomimetics;tactile sensing},
  doi={10.1109/LRA.2024.3387111},
  url={https://ieeexplore.ieee.org/abstract/document/10496158}, 
  html={https://ieeexplore.ieee.org/abstract/document/10496158},
  abstract={In this letter, we introduce a new soft biomimetic optical tactile sensor based on mimicking the interlocking structure of the epidermal-dermal boundary: the BioTacTip. The primary sensing unit comprises a sharp white tip surrounded by four black cover tips that when subjected to an external force emphasizes the applied direction and contact location, for high-resolution imaging by an internal camera. The sensor design means that we can utilize the tactile images directly as the model input (not requiring marker detection) for computationally efficient reconstruction of 3D external forces, contact geometry, localization and depth, by utilizing an analytic tactile model based on dynamic friction and internal pressure. Indentation and press-and-shear tests confirmed this mechanism, with sub-mm localization and indentation errors, and normal and shear force time series that match measured quantities. The sensor design opens up a new way to instantiate biomimicry in optical tactile sensors that utilizes mechanical processing in the skin.},
  selected = {true}
}


@ARTICLE{10153107,
abbr = {RAM},
  author={Perez, Julie Stephany Berrio and Psomopoulou, Efi and Ben Amor, Heni and Leidner, Daniel},
  journal={IEEE Robotics & Automation Magazine}, 
  title={Becoming a Plenary or Keynote Speaker in an International Robotics Conference: Perspectives From an IEEE RAS Women in Engineering Panel}, 
  year={2023},
  volume={30},
  number={2},
  pages={113-115},
  altmetric = {true},
  dimensions={true},
  doi={10.1109/MRA.2023.3266933},
  url={https://ieeexplore.ieee.org/document/10153107},
  html={https://ieeexplore.ieee.org/document/10153107},
  abstract={The IEEE Robotics and Automation Society (RAS) Women in Engineering Committee organized a virtual event for the 2022 International Conference on Robotics and Automation (ICRA) and was honored to host Lydia Kavraki, Katherine J. Kuchenbecker, and Vandi Verma as keynote speakers and panelists. These distinguished women have made significant contributions to the field of robotics and have been recognized for their exceptional achievements in research and education: they have all been past keynote or plenary speakers at a major international robotics conference. The presenters were invited to provide their valuable insights as women in the robotics field, engage with the attendees in meaningful conversations, and share their experiences and expertise. The event was held online in Gather, prior to the 2022 ICRA conference, to offer a platform for those unable to participate in the in-person event and to act as an icebreaker for early-career researchers who might be attending ICRA for the first time ( Figure 1 ). The event also enabled attendees to connect and network with other professionals in the field, as well as to contribute to the discussion on the critical topic of diversity and inclusivity in robotics.}
}

@INPROCEEDINGS{10161036,
abbr = {ICRA},
abstract={This paper presents a control scheme for force sensitive, gentle grasping with a Pisa/IIT anthropomorphic SoftHand equipped with a miniaturised version of the TacTip optical tactile sensor on all five fingertips. The tactile sensors provide high-resolution information about a grasp and how the fingers interact with held objects. We first describe a series of hardware developments for performing asynchronous sensor data acquisition and processing, resulting in a fast control loop sufficient for real-time grasp control. We then develop a novel grasp controller that uses tactile feedback from all five fingertip sensors simultaneously to gently and stably grasp 43 objects of varying geometry and stiffness, which is then applied to a human-to-robot handover task. These developments open the door to more advanced manipulation with underactuated hands via fast reflexive control using high-resolution tactile sensing.},
author={Ford, Christopher J. and Li, Haoran and Lloyd, John and Catalano, Manuel G. and Bianchi, Matteo and Psomopoulou, Efi and Lepora, Nathan F.},
booktitle={IEEE International Conference on Robotics and Automation}, 
title={Tactile-Driven Gentle Grasping for Human-Robot Collaborative Tasks}, 
year={2023},
volume={},
number={},
altmetric = {true},
dimensions={true},
pages={10394-10400},
keywords={Integrated optics;Optical feedback;Tactile sensors;Process control;Grasping;Handover;Real-time systems},
doi={10.1109/ICRA48891.2023.10161036},
eprint={2303.09346},
arxiv = {2303.09346},
video={https://www.youtube.com/embed/1ljw4J1nseo?si=PmrxHqilwUy3nNNn},
pdf={https://arxiv.org/pdf/2303.09346},
archivePrefix={arXiv},
primaryClass={cs.RO},
url={https://ieeexplore.ieee.org/document/10161036},
html={https://ieeexplore.ieee.org/document/10161036},
  }


@ARTICLE{10120615,
abbr = {POT},
abstract = {The development of robotic grippers is driven by the need to execute particular manual tasks or meet specific objectives in handling operations. Grippers with specific functions vary from being small, accurate, and highly controllable, such as the surgical tool effectors of the Da Vinci robot (designed to be used as noninvasive grippers controlled by a human operator during keyhole surgeries), to larger, highly controllable grippers like the Shadow Dexterous Hand (designed to recreate the hand motions of a human). Additionally, there are less finely controllable grippers, such as the iRobot-Harvard-Yale (iHY) Hand or iRobot-Harvard-Yale (IIT)-Pisa SoftHand, which, instead, leverage natural motions during grasping via designs inspired by observed biomechanical systems. As robotic systems become more autonomous and widely used, it is becoming increasingly important to consider the design, form, and function of robotic grippers.},
author={Cairnes, Thomas J. and Ford, Christopher J. and Psomopoulou, Efi and Lepora, Nathan},
journal={IEEE Potentials}, 
title={An overview of robotic grippers}, 
year={2023},
volume={42},
number={3},
pages={17-23},
altmetric = {true},
dimensions={true},
arxiv={2304.14051},
archivePrefix = {arXiv},
pdf={https://arxiv.org/pdf/2304.14051},
doi={10.1109/MPOT.2023.3236143},
url={https://ieeexplore.ieee.org/document/10120615},
html={https://ieeexplore.ieee.org/document/10120615}
}

@article{Li2022,
abbr = {RA-L},
abstract = {This letter introduces the BRL/Pisa/IIT (BPI) SoftHand: a single actuator-driven, low-cost, 3D-printed, tendon-driven, underactuated robot hand that can be used to perform a range of grasping tasks. Based on the adaptive synergies of the Pisa/IIT SoftHand, we design a new joint system and tendon routing to facilitate the inclusion of both soft and adaptive synergies, which helps us balance durability, affordability and grasping performance of the hand. The focus of this work is on the design, simulation, synergies and grasping tests of this SoftHand. The novel phalanges are designed and printed based on linkages, gear pairs and geometric restraint mechanisms, and can be applied to most tendon-driven robotic hands. We show that the robot hand can successfully grasp and lift various target objects and adapt to hold complex geometric shapes, reflecting the successful adoption of the soft and adaptive synergies. We intend to open-source the design of the hand so that it can be built cheaply on a home 3D-printer.},
author={Li, Haoran and Ford, Christopher J. and Bianchi, Matteo and Catalano, Manuel G. and Psomopoulou, Efi and Lepora, Nathan F.},
journal={IEEE Robotics and Automation Letters, IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
title={BRL/Pisa/IIT SoftHand: A Low-Cost, 3D-Printed, Underactuated, Tendon-Driven Hand With Soft and Adaptive Synergies}, 
year={2022},
archivePrefix = {arXiv},
arxiv = {2206.12655},
eprint = {2206.12655},
pdf = {https://arxiv.org/pdf/2206.12655},
volume={7},
number={4},
pages={8745-8751},
altmetric = {true},
dimensions={true},
video={https://www.youtube.com/embed/sRKxjtlK28A?si=3u2Kx7WLD2yAHGnD},
doi={10.1109/LRA.2022.3187876},
url = {https://ieeexplore.ieee.org/document/9813397},
html = {https://ieeexplore.ieee.org/document/9813397}
}


@article{Psomopoulou2021,
abbr = {RA-L},
abstract = {This paper proposes a controller for stable grasping of unknown-shaped objects by two robotic fingers with tactile fingertips. The grasp is stabilised by rolling the fingertips on the contact surface and applying a desired grasping force to reach an equilibrium state. The validation is both in simulation and on a fully-actuated robot hand (the Shadow Modular Grasper) fitted with custom-built optical tactile sensors (based on the BRL TacTip). The controller requires the orientations of the contact surfaces, which are estimated by regressing a deep convolutional neural network over the tactile images. Overall, the grasp system is demonstrated to achieve stable equilibrium poses on a range of objects varying in shape and softness, with the system being robust to perturbations and measurement errors. This approach also has promise to extend beyond grasping to stable in-hand object manipulation with multiple fingers.},
archivePrefix = {arXiv},
arxiv = {2106.01110},
journal = {Robotics & Automation Letters, IEEE/RSJ International Conference on Intelligent Robots and Systems},
author = {Psomopoulou, Efi and Pestell, Nicholas and Papadopoulos, Fotios and Lloyd, John and Doulgeri, Zoe and Lepora, Nathan F.},
eprint = {2106.01110},
pdf = {RAL_IROS_2021.pdf},
volume={6},
number={4},
pages={8150-8157},
altmetric = {true},
video={https://www.youtube.com/embed/rfQesw3FDA4?si=BFizQGJCdyP6CvAf},
dimensions={true},
url = {https://ieeexplore.ieee.org/document/9511836},
html = {https://ieeexplore.ieee.org/document/9511836},
title = {A Robust Controller for Stable 3D Pinching Using Tactile Sensing},
year = {2021},
doi={10.1109/LRA.2021.3104057},
selected = {true}
}


@inproceedings{Abeywardena2020,
abbr = {MEDICON},
abstract = {A novel master controller for robot-assisted minimally invasive surgery (RAMIS) is introduced and used to control a da Vinci EndoWrist instrument. The geometric model of the master mechanism and its mapping to the geometry of the EndoWrist tool are derived. Experimental results are conducted to open and close the jaws of an EndoWrist tool, and show that the developed mapping algorithm is accu- rate with a root mean square error of 0.7463 mm.},
author = {Abeywardena, Sajeeva and Psomopoulou, Efi and Sani, Mohammad Fattahi and Tzemanaki, Antonia and Dogramadzi, Sanja},
booktitle = {XV Mediterranean Conference on Medical and Biological Engineering and Computing},
doi = {10.1007/978-3-030-31635-8_191},
pdf = {MEDICON_Abey.pdf},
isbn = {9783030316358},
pages = {1545--1550},
altmetric = {true},
dimensions={true},
publisher = {Springer International Publishing},
title = {Control of a da Vinci EndoWrist Surgical Instrument Using a Novel Master Controller},
url = {http://link.springer.com/10.1007/978-3-030-31635-8_191},
html = {http://link.springer.com/10.1007/978-3-030-31635-8_191},
year = {2020}
}


@inproceedings{Sani2020,
abbr = {MEDICON},
abstract = {Robot Assisted Surgery is attracting increasing amount of attention as it offers numerous benefits to patients as well as surgeons. Heart surgery requires a high level of precision and dexterity, in con- trast to other surgical specialties. Robot assisted heart surgery is not as widely performed due to numerous reasons including a lack of appropri- ate and intuitive surgical interfaces to control minimally invasive surgi- cal tools. In this paper, finger motion of the surgeon is analyzed during cardiac surgery tasks on an ex-vivo animal model with the purpose of designing a more intuitive master console. First, a custom finger tracking system is developed using IMU sensors, which is lightweight and com- fortable enough to allow free movement of the surgeon's fingers/hands while using instruments. The proposed system tracks finger joint angles and fingertip positions for three involved fingers (thumb, index, mid- dle). Accuracy of the IMU sensors has been evaluated using an optical tracking system (Polaris, NDI). Finger motion of the cardiac surgeon while using a Castroviejo instrument is studied in suturing and knot- ting scenarios. The results show that PIP and MCP joints have larger Range Of Motion (ROM), and faster rate of change compared to other finger/thumb joints, while thumb has the largest Fingertip WorkSpace (FWS) of all three digits.},
author = {Sani, Mohammad Fattahi and Abeywardena, Sajeeva and Psomopoulou, Efi},
booktitle = {XV Mediterranean Conference on Medical and Biological Engineering and Computing},
doi = {10.1007/978-3-030-31635-8},
editor = {Henriques, Jorge and Neves, Nuno and de Carvalho, Paulo},
pdf = {MEDICON_Sani.pdf},
isbn = {978-3-030-31634-1},
pages = {1515--1525},
publisher = {Springer International Publishing},
series = {IFMBE Proceedings},
altmetric = {true},
dimensions={true},
title = {Towards Finger Motion Tracking and Analyses for Cardiac Surgery},
url = {http://link.springer.com/10.1007/978-3-030-31635-8},
html = {http://link.springer.com/10.1007/978-3-030-31635-8},
volume = {76},
year = {2020}
}


@inproceedings{Psomopoulou2020,
abbr = {MEDICON},
abstract = {A desktop haptic device is used to teleoperate an indus- trial redundant and compliant robotic arm with a surgical instrument mounted on its end-effector. The master and slave devices are coupled in a bilateral position-position architecture. Force feedback is provided by the master haptic device to the user, from the position of the slave's wrist. A surgical task (palpation) that involves force feedback is pre- sented and tested in a user study with surgeons and non-medical par- ticipants. Results show that users easily discern between three different materials during palpation given minimal familiarisation time. Active constraint enforcement is also integrated with the system as a sensitive area around the palpation samples which the slave instrument is prohib- ited to enter.},
author = {Psomopoulou, Efi and Persad, Raj and Koupparis, Anthony and Abeywardena, Sajeeva and Sani, Mohammad Fattahi and Melhuish, Chris and Dogramadzi, Sanja},
booktitle = {XV Mediterranean Conference on Medical and Biological Engineering and Computing},
doi = {10.1007/978-3-030-31635-8_194},
pdf = {MEDICON_Efi.pdf},
isbn = {9783030316358},
pages = {1571--1580},
altmetric = {true},
dimensions={true},
video={https://www.youtube.com/embed/ivSKAxDJ7S8?si=rBWB58_XyqrZTJBA},
publisher = {Springer International Publishing},
title = {Evaluation of Force Feedback for Palpation and Application of Active Constraints on a Teleoperated System},
url = {http://link.springer.com/10.1007/978-3-030-31635-8_194},
volume = {1},
html = {http://link.springer.com/10.1007/978-3-030-31635-8_194},
year = {2020}
}

@article{Abeywardena2019,
abbr = {FRONT},
abstract = {A new algorithm is proposed to estimate the tool-tissue force interaction in robot-assisted minimally invasive surgery which does not require the use of external force sensing. The proposed method utilises the current of the motors of the surgical instrument and neural network methods to estimate the force interaction. Offline and online testing is conducted to assess the feasibility of the developed algorithm. Results showed that the developed method has promise in allowing online estimation of tool-tissue force and could thus enable haptic feedback in robotic surgery to be provided.},
author = {Abeywardena, Sajeeva and Yuan, Qiaodi and Tzemanaki, Antonia and Psomopoulou, Efi and Droukas, Leonidas and Melhuish, Chris and Dogramadzi, Sanja},
doi = {10.3389/frobt.2019.00056},
issn = {2296-9144},
journal = {Frontiers in Robotics and AI},
keywords = {force estimation,haptic feedback,minimally invasive surgery,neural networks,sensor-less sensing},
month = {jul},
number = {July},
pages = {1--10},
altmetric = {true},
dimensions={true},
title = {Estimation of Tool-Tissue Forces in Robot-Assisted Minimally Invasive Surgery Using Neural Networks},
url = {https://www.frontiersin.org/article/10.3389/frobt.2019.00056/full},
html = {https://www.frontiersin.org/article/10.3389/frobt.2019.00056/full},
volume = {6},
year = {2019},
pdf = {FRONT_2019.pdf},
}

@article{Sidiropoulos2019,
abbr = {AURO},
abstract = {A handover strategy is proposed that aims at natural and fluent robot to human object handovers. For the approaching phase, a globally asymptotically stable dynamical system (DS) is utilized, trained from human demonstrations and exploiting the existence of mirroring in the human wrist motion. The DS operates in the robot task space thus achieving independence with respect to the robot platform, encapsulating the position and orientation of the human wrist within a single DS. It is proven that the motion generated by such a DS, having as target the current wrist pose of the receiver's hand, is bounded and converges to the previously unknown handover location. Haptic cues based on load estimates at the robot giver ensure full object load transfer before grip release. The proposed strategy is validated with simulations and experiments in real settings.},
author = {Sidiropoulos, Antonis and Psomopoulou, Efi and Doulgeri, Zoe},
doi = {10.1007/s10514-018-9705-x},
pdf = {AURO_2019.pdf},
issn = {0929-5593},
journal = {Autonomous Robots},
month = {aug},
number = {6},
pages = {1327--1342},
altmetric = {true},
dimensions={true},
video={https://www.youtube.com/embed/eWn1Kby0mK8?si=aGCMsAgTFnKVFw7o},
title = {A human inspired handover policy using Gaussian Mixture Models and haptic cues},
url = {http://link.springer.com/10.1007/s10514-018-9705-x},
html = {http://link.springer.com/10.1007/s10514-018-9705-x},
volume = {43},
year = {2019}
}

@inproceedings{Sayyaddelshad2018,
abbr = {CRAS},
author = {Sayyaddelshad, Iman and Psomopoulou, Efi and Abeywardena, Sajeeva and Tzemanaki, Antonia and Dogramadzi, Sanja},
booktitle = {Joint workshop on New Technologies for Computer/Robot Assisted Surgery},
pdf = {CRAS_2018_Iman.pdf},
pages = {2},
altmetric = {true},
title = {Incision Port Displacement Modelling Verification in Minimally Invasive Surgical Robots},
year = {2018}
}

@inproceedings{Tzemanaki2018,
abbr = {CRAS},
author = {Tzemanaki, Antonia and Abeywardena, Sajeeva and Psomopoulou, Efi and Melhuish, Chris and Dogramadzi, Sanja},
booktitle = {Joint workshop on New Technologies for Computer/Robot Assisted Surgery},
pdf = {CRAS_2018_Tzem.pdf},
pages = {2},
altmetric = {true},
title = {Using current measurement to estimate palpation and grasping forces in robot-assisted minimally invasive surgery},
year = {2018}
}

@article{2017,
abbr = {PhD},
abstract = {The thesis deals with the problem of grasping by robotic hands as well as the human-robot haptic interaction during object load transfer. A passivity-based stable grasping control law for unknown object weight is exploited and extended in order to be used in the design of two strategies for the safe and natural human-robot object load transfer which takes place in the direction of the gravity field. The controller is extended with respect to the desired grasping force and the object's mass that is allocated to the respective hand. The extension is based on human studies on the grasping and load forces that are developed by the giver and receiver. The first object load transfer strategy is initiated by the giver who linearly decreases its load and grip forces until the full release of the object’s load. It is assumed that the receiver estimates the load transfer successfully and adapts its grip forces accordingly to achieve an efficient object transfer, ie. the receiver is either a cooperative and healthy human or a robot. In case the receiver is not a fully responsive participant and does not or cannot instantly accept the released load, the force exchange is not linear and as a result the object slips from the grasp since the receiver's behaviour is not taken into account. The second strategy is receiver initiated and it involves a rich haptic interaction between the hands. In this strategy, the giver is a stably grasping robotic hand that follows closely the receiver’s lead and ensures haptically that the receiver has stably grasped the object before opening its grip. Therefore, the receiver can be anyone from a fully cooperative robot to an insufficiently responsive human. Theoretical design and validation via simulations are presented for both strategies, demonstrating the advantages of the receiver initiated strategy. This strategy is generalized for cases where the robot's fingers do not possess rolling capabilities on the object's surface and for cases where the load transfer does not take place in the direction of the gravity field. The strategy is also integrated with an arm motion controller to complete the hand-over procedure and is validated by both simulations and experimental results. Consequently, the control law used in the object load transfer strategies is extended for a weightless object in order to achieve control objectives regarding the optimal grasping force which may vary for different kinds of objects or the robot's subsequent desired task following the stable object grasp. This is achieved by controlling the fingers' desired relative orientation in the rolling direction by the a priori optimization of the internal force manipulability ellipsoid. Theoretical design and validation via both simulations and experimental results are presented for the proposed controller, demonstrating its effectiveness. Last, the grasping controller is extended to the three dimensional space where the fingers' desired relative orientation is controlled with respect to two rolling directions on the contact surface. The definition of these directions determines the in-hand object manipulability. Simulation results are presented that validate the theoretical analysis.},
author = {Psomopoulou, Efi},
school = {Aristotle University of Thessaloniki},
journal = {PhD Thesis},
altmetric = {true},
title = {Stable grasping and robot-to-human object load transfer},
pages = {188},
url = {https://www.didaktorika.gr/eadd/handle/10442/42252?locale=en},
html = {https://www.didaktorika.gr/eadd/handle/10442/42252?locale=en},
year = {2017}
}


@inproceedings{Psomopoulou2015,
abbr = {IROS},
abstract = {A human-inspired hand-over control strategy is proposed for the haptic interaction of two dual-fingered hands for the planar case. It is based on a grasp controller for an unknown object which achieves, via fingertip rolling, a stable grasp and a real object mass estimation. Object load transfer is receiver initiated, follows human evidence and involves awareness of the other hand’s state based solely on local proprioceptive measurements. Simulation results illustrate the proposed approach.},
author = {Psomopoulou, Efi and Doulgeri, Zoe},
booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2015.7353417},
pdf = {IROS_2015.pdf},
isbn = {978-1-4799-9994-1},
month = {sep},
pages = {491--496},
publisher = {IEEE},
altmetric = {true},
dimensions={true},
title = {A human inspired stable object load transfer for robots in hand-over tasks},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7353417},
html = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7353417},
year = {2015}
}

@inproceedings{Psomopoulou2015b,
abbr = {RSS},
abstract = {A human-inspired hand-over control strategy is
proposed for the haptic interaction of two dual-fingered hands. It can be applied to robots that are intended to assist older adults and people with motor impairments and it focuses on the timing and synchronization which is required for a successful object load transfer.},
author = {Psomopoulou, Efi and Doulgeri, Zoe},
booktitle = {Robotics: Science and Systems Conference},
pdf = {RSS_2015.pdf},
pages = {4},
altmetric = {true},
title = {Human-inspired object load transfer in hand-over tasks},
year = {2015}
}

@inproceedings{Psomopoulou2014,
abbr = {MED},
abstract = {A robot hand-over control scheme is proposed
achieving human-like haptic interaction during object load transfer from a giver to a receiver hand for the planar case. It is assumed that the object has parallel surfaces and unknown mass. The giver initiates the hand-over process while the receiver estimates the transferred object mass adapting its grip force accordingly in a three stage process. The control laws are based on a dynamically stable grasp controller which is modified for the hand-over task. A stable load transfer is securely achieved as shown by the theoretical analysis and illustrated by the simulation results.},
address = {Palermo},
author = {Psomopoulou, Efi and Doulgeri, Zoe},
booktitle = {22nd Mediterranean Conference on Control and Automation},
doi = {10.1109/MED.2014.6961583},
pdf = {MED_2014.pdf},
isbn = {978-1-4799-5901-3},
month = {jun},
pages = {1470--1475},
publisher = {IEEE},
altmetric = {true},
dimensions={true},
title = {A robot hand-over control scheme for human-like haptic interaction},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6961583},
html = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6961583},
year = {2014}
}

@inproceedings{Psomopoulou2012,
abbr = {IROS},
abstract = {In this paper a simple tracking controller for a variable stiffness joint is proposed. System dynamics is considered unknown. The controller guarantees link and stiffness motor position performance specifications that have been apriori set, utilizing full state feedback. Simulation results on the previously published CompAct-VSA joint validate the efficiency of the proposed control approach.},
address = {Vilamoura, Algarve, Portugal},
author = {Psomopoulou, Efi and Doulgeri, Zoe and Rovithakis, George A and Tsagarakis, Nikos G},
booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2012.6385859},
pdf = {IROS_2012.pdf},
isbn = {978-1-4673-1736-8},
issn = {21530858},
month = {oct},
pages = {5071--5076},
altmetric = {true},
dimensions={true},
publisher = {IEEE},
title = {A simple controller for a variable stiffness joint with uncertain dynamics and prescribed performance guarantees},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6385859},
html = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6385859},
year = {2012}
}

@article{Psomopoulou2018,
abbr = {ROB},
abstract = {There is a large gap between reality and grasp models that are currently available because of the static analysis that characterizes these approaches. This work attempts to fill this need by proposing a control law that, starting from an initial contact state which does not necessarily correspond to an equilibrium, achieves dynamically a stable grasp and a relative finger orientation in the case of pinching an object with arbitrary shape via rolling soft fingertips. Controlling relative finger orientation may improve grasping force manipulability and allow the appropriate shaping of the composite object consisted of the distal links and the object, for facilitating subsequent tasks. The proposed controller utilizes only finger proprioceptive measurements and is not based on the system model. Simulation and experimental results demonstrate the performance of the proposed controller with objects of different shapes.},
author = {Psomopoulou, Efi and Karashima, Daiki and Doulgeri, Zoe and Tahara, Kenji},
doi = {10.1017/S0263574717000303},
pdf = {ROBOTICA.pdf},
isbn = {0263574717},
issn = {0263-5747},
journal = {Robotica},
month = {feb},
number = {2},
pages = {204--224},
altmetric = {true},
dimensions={true},
google_scholar ={true},
video={https://www.youtube.com/embed/A6WuCj2WzzM?si=SSgpTvnK0NBU8QXr},
title = {Stable pinching by controlling finger relative orientation of robotic fingers with rolling soft tips},
url = {https://www.cambridge.org/core/product/identifier/S0263574717000303/type/journal_article},
html = {https://www.cambridge.org/core/product/identifier/S0263574717000303/type/journal_article},
volume = {36},
year = {2018}
}

@inproceedings{Grammatikopoulou2014,
abbr = {ICRA},
abstract = {This paper proposes a controller for the stable
grasp of an arbitrary-shaped object on the horizontal plane by two robotic fingers with rigid hemispherical fingertips. The controller stabilizes the grasp with optimal force angles and desired finger shaping determined through the choice of a control constant without requiring the utilization of any contact information regarding contact locations and contact angles or any estimates of them. Simulation results demonstrate the performance of the proposed controller and show its clear advantages with respect to other known control schemes.},
author = {Grammatikopoulou, Maria and Psomopoulou, Efi and Droukas, Leonidas and Doulgeri, Zoe},
booktitle = {IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2014.6907389},
pdf = {ICRA_2014.pdf},
isbn = {978-1-4799-3685-4},
month = {may},
pages = {3662--3668},
publisher = {IEEE},
altmetric = {true},
dimensions={true},
google_scholar ={true},
title = {A controller for stable grasping and desired finger shaping without contact sensing},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6907389},
html = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6907389},
year = {2014}
}

@article{Psomopoulou2015,
abbr = {TCST},
abstract = {This paper is concerned with the design of a state
feedback control scheme for variable stiffness actuated (VSA) robots, which guarantees prescribed performance of the track- ing errors despite the low range of mechanical stiffness. The controller does not assume knowledge of the actual system dynamics nor does it utilize approximating structures (e.g., neural networks and fuzzy systems) to acquire such knowledge, leading to a low complexity design. Simulation studies, incorporating a model validated on data from an actual variable stiffness actuator (VSA) at a multi-degrees-of-freedom robot, are performed. Com- parison with a gain scheduling solution reveals the superiority of the proposed scheme with respect to performance and robustness.},
author = {Psomopoulou, Efi and Theodorakopoulos, Achilles and Doulgeri, Zoe and Rovithakis, George A},
doi = {10.1109/TCST.2015.2394748},
pdf = {TCST_2015.pdf},
issn = {1063-6536},
journal = {IEEE Transactions on Control Systems Technology},
month = {sep},
number = {5},
pages = {1914--1926},
altmetric = {true},
dimensions={true},
google_scholar ={true},
title = {Prescribed Performance Tracking of a Variable Stiffness Actuated Robot},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7051223},
html = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7051223},
volume = {23},
year = {2015},
selected = {true}
}


